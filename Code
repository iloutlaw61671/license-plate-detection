# Number plate detection


import cv2
import imutils
import numpy as np  #importing required libraries
import pytesseract
pytesseract.pytesseract.tesseract_cmd =r"C:\Program Files\Tesseract-OCR\tesseract.exe"   #text recognition software

cap = cv2.VideoCapture(0)  
kernel = np.ones((2,2),np.uint8)
cntr=0
while 1:
    cntr=cntr+1
    if (cntr%20)==0:  #leaving 20 every 20 frame
        ret, frame = cap.read()
        frame = cv2.resize(frame, (620,480) )
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        gray = cv2.bilateralFilter(gray, 13, 15, 15)                     #making the image grayscale
        imgH,imgW,_ = frame.shape
        x1,y1,w1,h1=0,0,imgH,imgW
        edged = cv2.Canny(gray, 100, 200)               #seperating edges
        thresh = cv2.dilate(edged,kernel,iterations = 5)
        contours=cv2.findContours(edged,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)  #finding contours in frame
        contours = imutils.grab_contours(contours)
        contours = sorted(contours,key=cv2.contourArea, reverse = True)[:10]   #take first 10 largest objects
        screenCnt = None
        
        for i,c in enumerate(contours):
                                          # approximate the contour
           peri = cv2.arcLength(c, True)
           approx = cv2.approxPolyDP(c, 0.018 * peri, True)
           if len(approx) == 4:                               #Seperating contours with rectangular shape (like liscence plate)
                screenCnt = approx
                my_index = i
                break
        if screenCnt is None:                                 #required contour stored in screenCnt
            detected = 0
            print ("No contour detected")
        else:
            detected = 1

        if detected == 1:
                 mask = np.zeros_like(gray)                                         #seperating and cropping image of contour
                 new_image = cv2.drawContours(mask,[screenCnt],0,255,-1,)
                 xq,yq,wq,hq = cv2.boundingRect(screenCnt)                  
                 new_image = cv2.bitwise_and(frame,frame,mask=mask)
                 new_image = new_image[yq:yq+hq, xq:xq+wq]   
                 imgbox= pytesseract.image_to_boxes(new_image)                        #character detection using Tesseract
                 imgchar= pytesseract.image_to_string(new_image,config='--psm 11')
            
        for boxes in imgbox.splitlines():                                             #detecting each character in Contour                                          
                 boxes = boxes.split(' ')
                 x,y,w,h=int(boxes[1]),int(boxes[2]),int(boxes[3]),int(boxes[4])
                 cv2.rectangle(frame,(x,imgH-y),(w,imgH-h),(0,0,255),3)
                 x2,y2,w2,h2 = cv2.boundingRect(screenCnt)
                 cv2.putText(frame, imgchar, (x2+w2,y2+h2), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)
                 print("Detected license plate Number is:",imgchar)
        
        cv2.imshow('frame',frame)                                                      #display
        cv2.imshow('new',new_image)
                                                                                 
        
        if cv2.waitKey(1) & 0xFF == ord('q'):
              break

# When everything done, release the capture
cap.release()
cv2.destroyAllWindows()
